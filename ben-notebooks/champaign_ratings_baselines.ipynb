{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing baseline Yelp business ratings for Champaign, IL\n",
    "\n",
    "This notebook follows guidelines in [this guide to collaborative filtering systems](http://files.grouplens.org/papers/FnT%20CF%20Recsys%20Survey.pdf) to compute simple baselines for recommender system predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "US_CANADA_REGION_BY_STATE_DICT = {\n",
    "    'AZ': 'Phoenix',\n",
    "    'NV': 'Las Vegas',\n",
    "    'ON': 'Toronto',\n",
    "    'NC': 'Charlotte',\n",
    "    'SC': 'Charlotte',\n",
    "    'OH': 'Cleveland',\n",
    "    'PA': 'Pittsburgh',\n",
    "    'QC': 'Montreal',\n",
    "    'NY': 'Montreal',\n",
    "    'VT': 'Montreal',\n",
    "    'WI': 'Madison',\n",
    "    'IL': 'Champaign'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "all_reviews_file = '../raw-data/yelp_academic_dataset_review.json'\n",
    "all_businesses_file = '../raw-data/yelp_academic_dataset_business.json'\n",
    "champaign_reviews_file = '../preprocessed-data/all-champaign-reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_businesses_df(json_file_name, select_keys=None, us_canada_only=True):\n",
    "    \"\"\" Return dataframe from raw data.\n",
    "    All rows unless max_rows is set. All cities unless city is set. All columns unless select_keys is set.\n",
    "    Only businesses in US/Canada if us_canada_only is true\n",
    "    \"\"\"\n",
    "    with open(json_file_name, 'r') as f:\n",
    "        i_row = 0\n",
    "        df_dict_list = []\n",
    "        for line in f:\n",
    "            row_dict = json.loads(line)\n",
    "            if us_canada_only:\n",
    "                if row_dict['state'] not in US_CANADA_REGION_BY_STATE_DICT.keys():\n",
    "                    continue\n",
    "            if select_keys is not None:\n",
    "                select_keys = set(select_keys)\n",
    "                select_keys.add('business_id') # make sure to keep business_id no matter what\n",
    "                row_dict = {k: row_dict[k] for k in select_keys} # get dict of subset of keys/columns\n",
    "            df_dict_list.append(row_dict)\n",
    "            i_row += 1\n",
    "        df = pd.DataFrame(df_dict_list)\n",
    "        df = df.set_index('business_id')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews_df(json_file_name, df_businesses, city=None, max_rows=None,\n",
    "                   select_keys=None, keep_rand_frac=None, seed=None):\n",
    "    \"\"\" Return dataframe from raw data.\n",
    "    All rows unless max_rows is set. All cities unless city is set. All columns unless select_keys is set.\n",
    "    \"\"\"\n",
    "    if keep_rand_frac is not None:\n",
    "        if seed is None:\n",
    "            random.seed()\n",
    "        else:\n",
    "            random.seed(seed)\n",
    "    with open(json_file_name, 'r') as f:\n",
    "        i_row = 0\n",
    "        df_dict_list = []\n",
    "        for line in f:\n",
    "            row_dict = json.loads(line)\n",
    "            if city:\n",
    "                b_id = row_dict['business_id']\n",
    "                if df_businesses.loc[b_id, 'city'] != city:\n",
    "                    continue\n",
    "            if select_keys is not None:\n",
    "                select_keys = set(select_keys)\n",
    "                select_keys.add('review_id') # make sure to keep business_id no matter what\n",
    "                select_keys.add('user_id') # make sure to keep user_id no matter what\n",
    "                select_keys.add('business_id') # make sure to keep user_id no matter what\n",
    "                row_dict = {k: row_dict[k] for k in select_keys}\n",
    "            if (keep_rand_frac is None) or ((keep_rand_frac is not None) and (random.random() < keep_rand_frac)):\n",
    "                df_dict_list.append(row_dict)\n",
    "                i_row += 1\n",
    "                if (max_rows is not None) and (i_row >= max_rows):\n",
    "                    break\n",
    "        df = pd.DataFrame(df_dict_list)\n",
    "        df = df.set_index('review_id')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Businesses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144072 total businesses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0DI8Dt2PJp07XkVvIElIcQ</th>\n",
       "      <td>33.378214</td>\n",
       "      <td>-111.936102</td>\n",
       "      <td>Innovative Vapors</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTlCaCGZE14GuaUXUGbamg</th>\n",
       "      <td>36.192284</td>\n",
       "      <td>-115.159272</td>\n",
       "      <td>Cut and Taste</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDqCEAGXVGCH4FJXgqtjqg</th>\n",
       "      <td>43.661054</td>\n",
       "      <td>-79.429089</td>\n",
       "      <td>Pizza Pizza</td>\n",
       "      <td>ON</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnGIivYRLxpF7tBVR_JwWA</th>\n",
       "      <td>40.444544</td>\n",
       "      <td>-80.174540</td>\n",
       "      <td>Plush Salon and Spa</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdk-qqJ71q6P7TJTww_DSA</th>\n",
       "      <td>43.659829</td>\n",
       "      <td>-79.375401</td>\n",
       "      <td>Comfort Inn</td>\n",
       "      <td>ON</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         latitude   longitude                 name state  \\\n",
       "business_id                                                                \n",
       "0DI8Dt2PJp07XkVvIElIcQ  33.378214 -111.936102    Innovative Vapors    AZ   \n",
       "LTlCaCGZE14GuaUXUGbamg  36.192284 -115.159272        Cut and Taste    NV   \n",
       "EDqCEAGXVGCH4FJXgqtjqg  43.661054  -79.429089          Pizza Pizza    ON   \n",
       "cnGIivYRLxpF7tBVR_JwWA  40.444544  -80.174540  Plush Salon and Spa    PA   \n",
       "cdk-qqJ71q6P7TJTww_DSA  43.659829  -79.375401          Comfort Inn    ON   \n",
       "\n",
       "                              city  \n",
       "business_id                         \n",
       "0DI8Dt2PJp07XkVvIElIcQ     Phoenix  \n",
       "LTlCaCGZE14GuaUXUGbamg   Las Vegas  \n",
       "EDqCEAGXVGCH4FJXgqtjqg     Toronto  \n",
       "cnGIivYRLxpF7tBVR_JwWA  Pittsburgh  \n",
       "cdk-qqJ71q6P7TJTww_DSA     Toronto  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['name', 'state', 'latitude', 'longitude']\n",
    "df_businesses = get_businesses_df(all_businesses_file, select_keys=keys, us_canada_only=False)\n",
    "df_businesses['city'] = df_businesses['state'].map(US_CANADA_REGION_BY_STATE_DICT)\n",
    "print('{} total businesses'.format(len(df_businesses)))\n",
    "df_businesses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29874 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3xGR24wD5ILntyX2UXZWTA</th>\n",
       "      <td>1DedueD53YsKcpqMWPIe9w</td>\n",
       "      <td>3</td>\n",
       "      <td>OkZk0I2S6mcMOtjSP12U_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_BvxFBvtyMKjNf3gzmbqw</th>\n",
       "      <td>1DedueD53YsKcpqMWPIe9w</td>\n",
       "      <td>4</td>\n",
       "      <td>8f9m9EdA6M5Jr-sqdPrc5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V926hjwKcbT-ZVJOwSeXnQ</th>\n",
       "      <td>1DedueD53YsKcpqMWPIe9w</td>\n",
       "      <td>2</td>\n",
       "      <td>oJl-C8UECsibhHS2dB8yzQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HBcuWFsU-6VrvzYZUDZQzA</th>\n",
       "      <td>1DedueD53YsKcpqMWPIe9w</td>\n",
       "      <td>5</td>\n",
       "      <td>XLwW5c_194tekHBy6ee7eg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnO18xosHxN5E8tKtI3AGA</th>\n",
       "      <td>1DedueD53YsKcpqMWPIe9w</td>\n",
       "      <td>5</td>\n",
       "      <td>qJfW5-Z890LfBV62xDqzUQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   business_id  stars                 user_id\n",
       "review_id                                                                    \n",
       "3xGR24wD5ILntyX2UXZWTA  1DedueD53YsKcpqMWPIe9w      3  OkZk0I2S6mcMOtjSP12U_A\n",
       "2_BvxFBvtyMKjNf3gzmbqw  1DedueD53YsKcpqMWPIe9w      4  8f9m9EdA6M5Jr-sqdPrc5A\n",
       "V926hjwKcbT-ZVJOwSeXnQ  1DedueD53YsKcpqMWPIe9w      2  oJl-C8UECsibhHS2dB8yzQ\n",
       "HBcuWFsU-6VrvzYZUDZQzA  1DedueD53YsKcpqMWPIe9w      5  XLwW5c_194tekHBy6ee7eg\n",
       "fnO18xosHxN5E8tKtI3AGA  1DedueD53YsKcpqMWPIe9w      5  qJfW5-Z890LfBV62xDqzUQ"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isfile(champaign_reviews_file):\n",
    "    # If you don't already have the champaign reviews csv, this will generate it.\n",
    "    # It took 20 minutes on my computer.\n",
    "    %%time\n",
    "    keys = ['stars']\n",
    "    df_reviews = get_reviews_df(all_reviews_file, df_businesses, city='Champaign', select_keys=keys)\n",
    "    df_reviews.to_csv('../preprocessed-data/all-champaign-reviews.csv')\n",
    "else:\n",
    "    df_reviews = pd.read_csv('../preprocessed-data/all-champaign-reviews.csv')\n",
    "    df_reviews = df_reviews.set_index('review_id')\n",
    "    print('{} reviews'.format(len(df_reviews)))\n",
    "    \n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 10022 | Number of businesses = 1556\n"
     ]
    }
   ],
   "source": [
    "n_users = df_reviews['user_id'].unique().shape[0]\n",
    "n_businesses = df_reviews['business_id'].unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + ' | Number of businesses = ' + str(n_businesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rating: 3.6055432817834907\n"
     ]
    }
   ],
   "source": [
    "mean_rating = df_reviews['stars'].mean()\n",
    "print('Mean rating: {}'.format(mean_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the average rating of the training data\n",
    "\n",
    "This uses the simple baseline prediction of $b_{u,i} = \\mu$ as mentioned in 2.1 of the collaborative filtering guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: RMSE = 1.4127093492278564\n",
      "Fold 1: RMSE = 1.419392931917939\n",
      "Fold 2: RMSE = 1.4234855168786251\n",
      "Fold 3: RMSE = 1.4185792824843677\n",
      "Fold 4: RMSE = 1.4139278697584874\n",
      "\n",
      "Average Error: 1.417618990053455\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "errors = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_reviews)):\n",
    "    df_train, df_test = df_reviews.iloc[train_index,:], df_reviews.iloc[test_index,:]\n",
    "    y_pred = df_train['stars'].mean() * np.ones(len(df_test))\n",
    "    err = rmse(df_test['stars'], y_pred)\n",
    "    errors.append(err)\n",
    "    print('Fold {}: RMSE = {}'.format(i, err))\n",
    "\n",
    "print('\\nAverage Error: {}'.format(np.mean(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with User's average rating\n",
    "\n",
    "This baseline averages all of the user's ratings to give the prediction for each rating. This is $b_{u,i} = \\bar{r_u}$ as mentioned in section 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: RMSE = 1.4905474126401397\n",
      "Fold 1: RMSE = 1.4919646222610048\n",
      "Fold 2: RMSE = 1.496843610432585\n",
      "Fold 3: RMSE = 1.4840542152537801\n",
      "Fold 4: RMSE = 1.4681452332359883\n",
      "\n",
      "Average Error: 1.4863110187646995\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "errors = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_reviews)):\n",
    "    df_train, df_test = df_reviews.iloc[train_index,:], df_reviews.iloc[test_index,:]\n",
    "    train_mean = df_train['stars'].mean()\n",
    "    user_means = df_train.groupby('user_id').mean().rename(columns={'stars': 'mean_user'})\n",
    "    df_test = df_test.join(user_means, on='user_id').fillna(train_mean)\n",
    "    err = rmse(df_test['stars'], df_test['mean_user'])\n",
    "    errors.append(err)\n",
    "    print('Fold {}: RMSE = {}'.format(i, err))\n",
    "\n",
    "print('\\nAverage Error: {}'.format(np.mean(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Business's average rating\n",
    "\n",
    "This is $b_{u,i} = \\bar{r_i}$ from section 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: RMSE = 1.307568254149668\n",
      "Fold 1: RMSE = 1.2963818607924362\n",
      "Fold 2: RMSE = 1.3044196993787507\n",
      "Fold 3: RMSE = 1.3071222719786242\n",
      "Fold 4: RMSE = 1.3168544145379486\n",
      "\n",
      "Average Error: 1.3064693001674854\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "errors = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_reviews)):\n",
    "    df_train, df_test = df_reviews.iloc[train_index,:], df_reviews.iloc[test_index,:]\n",
    "    train_mean = df_train['stars'].mean()\n",
    "    bus_means = df_train.groupby('business_id').mean().rename(columns={'stars': 'mean_bus'})\n",
    "    df_test = df_test.join(bus_means, on='business_id').fillna(train_mean)\n",
    "    err = rmse(df_test['stars'], df_test['mean_bus'])\n",
    "    errors.append(err)\n",
    "    print('Fold {}: RMSE = {}'.format(i, err))\n",
    "\n",
    "print('\\nAverage Error: {}'.format(np.mean(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict with a business and user baseline\n",
    "\n",
    "This is equation 2.1 from section 2.1 of the collaborative filtering guide. The equation is:\n",
    "\n",
    "$$b_{u_i} = \\mu + b_u + b_i$$\n",
    "\n",
    "where\n",
    "\n",
    "$$b_u = \\frac{1}{|I_u|}\\sum_{i \\in I_u} (r_{u,i} - \\mu)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$b_i = \\frac{1}{|U_i|}\\sum_{u \\in U_i} (r_{u,i} - b_u - \\mu)$$\n",
    "\n",
    "(See equations 2.2 and 2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: RMSE = 1.4235157070620779\n",
      "Fold 1: RMSE = 1.4260768578617162\n",
      "Fold 2: RMSE = 1.428865294847576\n",
      "Fold 3: RMSE = 1.4100757175658603\n",
      "Fold 4: RMSE = 1.4099408738397532\n",
      "\n",
      "Average Error: 1.4196948902353967\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "errors = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_reviews)):\n",
    "    df_train, df_test = df_reviews.iloc[train_index,:], df_reviews.iloc[test_index,:]\n",
    "    # Get mean rating of all training ratings\n",
    "    train_mean = df_train['stars'].mean()\n",
    "    # Get dataframe of b_u part of baseline for each user id\n",
    "    df_train_user = df_train[['user_id', 'stars']].groupby('user_id').mean().rename(columns={'stars': 'user_mean'})\n",
    "    df_train_user['b_u'] = df_train_user['user_mean'] - train_mean\n",
    "    # Create column of b_u values corresponding to the user who made the review\n",
    "    df_train = df_train.join(df_train_user['b_u'], on='user_id')\n",
    "    # Add column which will turn into b_i when averaging over each business\n",
    "    df_train['b_i'] = df_train['stars'] - df_train['b_u'] - train_mean\n",
    "    # Average over each business to get the actual b_i values for each business\n",
    "    df_train_bus = df_train[['business_id', 'b_i']].groupby('business_id').mean()\n",
    "    # Join b_u and b_i columns to test dataframe\n",
    "    df_test = df_test.join(df_train_user['b_u'], on='user_id').fillna(df_train_user['b_u'].mean())\n",
    "    df_test = df_test.join(df_train_bus['b_i'], on='business_id').fillna(df_train_bus['b_i'].mean())\n",
    "    # Predict and Compute error\n",
    "    err = rmse(df_test['stars'], df_test['b_u'] + df_test['b_i'] + train_mean)\n",
    "    errors.append(err)\n",
    "    print('Fold {}: RMSE = {}'.format(i, err))\n",
    "\n",
    "print('\\nAverage Error: {}'.format(np.mean(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict with a business and user baseline including damping terms\n",
    "\n",
    "This follows the same equation 2.1 from above ($b_{u_i} = \\mu + b_u + b_i$), but $b_u$ and $b_i$ are defined in a kind of Bayesian way. Specifically, damping factors are added in to push them closer to zero, making the baselines closer to the global average the lower the number of reviews. The equations for $b_u$ and $b_i$ here are\n",
    "\n",
    "$$b_u = \\frac{1}{|I_u| + \\beta_u}\\sum_{i \\in I_u} (r_{u,i} - \\mu)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$b_i = \\frac{1}{|U_i| + \\beta_i}\\sum_{u \\in U_i} (r_{u,i} - b_u - \\mu)$$\n",
    "\n",
    "(See equations 2.4 and 2.5) where $\\beta_u$ and $\\beta_i$ are damping factors, for which the guide reported 25 is a good number. 5 seems to work better in this case though, maybe because it's a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: RMSE = 1.2694763779129867\n",
      "Fold 1: RMSE = 1.2686029812582706\n",
      "Fold 2: RMSE = 1.2803895811347372\n",
      "Fold 3: RMSE = 1.266922460881656\n",
      "Fold 4: RMSE = 1.2690870521819977\n",
      "\n",
      "Average Error: 1.2708956906739295\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "beta_u, beta_i = 5, 5\n",
    "errors = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_reviews)):\n",
    "    df_train, df_test = df_reviews.iloc[train_index,:], df_reviews.iloc[test_index,:]\n",
    "    # Get mean rating of all training ratings\n",
    "    train_mean = df_train['stars'].mean()\n",
    "    # Get dataframe of b_u part of baseline for each user id\n",
    "    user_group = df_train[['user_id', 'stars']].groupby('user_id')\n",
    "    df_train_user = user_group.sum().rename(columns={'stars': 'sum'})\n",
    "    df_user_counts = pd.DataFrame(user_group.size(), columns=['count'])\n",
    "    df_train_user = pd.concat([df_train_user, df_user_counts], axis=1)\n",
    "    df_train_user['b_u'] = (df_train_user['sum'] - train_mean * df_train_user['count'])\n",
    "    df_train_user['b_u'] /= (df_train_user['count'] + beta_u)\n",
    "    # Create column of b_u values corresponding to the user who made the review\n",
    "    df_train = df_train.join(df_train_user['b_u'], on='user_id')\n",
    "    # Add column representing the expression inside the summation part of the b_i equation\n",
    "    df_train['b_i_sum'] = df_train['stars'] - df_train['b_u'] - train_mean\n",
    "    # Average over each business to get the actual b_i values for each business\n",
    "    bus_group = df_train[['business_id', 'b_i_sum']].groupby('business_id')\n",
    "    df_train_bus = bus_group.sum().rename(columns={'b_i_sum': 'b_i'})\n",
    "    df_train_bus['b_i'] /= bus_group.size() + beta_i\n",
    "    # Join b_u and b_i columns to test dataframe\n",
    "    df_test = df_test.join(df_train_user['b_u'], on='user_id').fillna(df_train_user['b_u'].mean())\n",
    "    df_test = df_test.join(df_train_bus['b_i'], on='business_id').fillna(df_train_bus['b_i'].mean())\n",
    "    # Predict and Compute error\n",
    "    err = rmse(df_test['stars'], df_test['b_u'] + df_test['b_i'] + train_mean)\n",
    "    errors.append(err)\n",
    "    print('Fold {}: RMSE = {}'.format(i, err))\n",
    "\n",
    "print('\\nAverage Error: {}'.format(np.mean(errors)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
